{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "BOs8l4Idgowy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KE242V4iOxfs"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_summarization(\n",
        "    temperature: float,\n",
        "    project_id: str,\n",
        "    location: str,\n",
        ") -> str:\n",
        "    \"\"\"Summarization Example with a Large Language Model\"\"\"\n",
        "\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "    # TODO developer - override these parameters as needed:\n",
        "    parameters = {\n",
        "        \"temperature\": temperature,  # Temperature controls the degree of randomness in token selection.\n",
        "        \"max_output_tokens\": 256,  # Token limit determines the maximum amount of text output.\n",
        "        \"top_p\": 0.95,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
        "        \"top_k\": 40,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
        "    }\n",
        "\n",
        "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "    response = model.predict(\n",
        "        \"\"\"Provide a summary with about following sentences for the following article:\n",
        "{text}\n",
        "Summary:\n",
        "\"\"\",\n",
        "        **parameters,\n",
        "    )\n",
        "    print(f\"Response from Model: {response.text}\")\n",
        "\n",
        "    return response.text\n",
        "\n"
      ],
      "metadata": {
        "id": "gPuxcnJBf3Kh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summarization()"
      ],
      "metadata": {
        "id": "Gtz7YDq3gLpg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}